{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc71cc5",
   "metadata": {},
   "source": [
    "## IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "424a1b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5273c45f",
   "metadata": {},
   "source": [
    "## READING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d97e80d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (581012, 55)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1   2    3    4     5    6    7    8     9   ...  45  46  47  48  \\\n",
       "0  2596   51   3  258    0   510  221  232  148  6279  ...   0   0   0   0   \n",
       "1  2590   56   2  212   -6   390  220  235  151  6225  ...   0   0   0   0   \n",
       "2  2804  139   9  268   65  3180  234  238  135  6121  ...   0   0   0   0   \n",
       "3  2785  155  18  242  118  3090  238  238  122  6211  ...   0   0   0   0   \n",
       "4  2595   45   2  153   -1   391  220  234  150  6172  ...   0   0   0   0   \n",
       "\n",
       "   49  50  51  52  53  54  \n",
       "0   0   0   0   0   0   5  \n",
       "1   0   0   0   0   0   5  \n",
       "2   0   0   0   0   0   2  \n",
       "3   0   0   0   0   0   2  \n",
       "4   0   0   0   0   0   5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url = (\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz\"\n",
    ")\n",
    "raw_data = pd.read_csv(data_url, header=None)\n",
    "print(f\"Dataset shape: {raw_data.shape}\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17bf0f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (581012, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Elevation</th>\n",
       "      <td>2596</td>\n",
       "      <td>2590</td>\n",
       "      <td>2804</td>\n",
       "      <td>2785</td>\n",
       "      <td>2595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspect</th>\n",
       "      <td>51</td>\n",
       "      <td>56</td>\n",
       "      <td>139</td>\n",
       "      <td>155</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slope</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <td>258</td>\n",
       "      <td>212</td>\n",
       "      <td>268</td>\n",
       "      <td>242</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <td>0</td>\n",
       "      <td>-6</td>\n",
       "      <td>65</td>\n",
       "      <td>118</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <td>510</td>\n",
       "      <td>390</td>\n",
       "      <td>3180</td>\n",
       "      <td>3090</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <td>221</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <td>232</td>\n",
       "      <td>235</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <td>148</td>\n",
       "      <td>151</td>\n",
       "      <td>135</td>\n",
       "      <td>122</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <td>6279</td>\n",
       "      <td>6225</td>\n",
       "      <td>6121</td>\n",
       "      <td>6211</td>\n",
       "      <td>6172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area</th>\n",
       "      <td>area_type_1</td>\n",
       "      <td>area_type_1</td>\n",
       "      <td>area_type_1</td>\n",
       "      <td>area_type_1</td>\n",
       "      <td>area_type_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type</th>\n",
       "      <td>soil_type_29</td>\n",
       "      <td>soil_type_29</td>\n",
       "      <td>soil_type_12</td>\n",
       "      <td>soil_type_30</td>\n",
       "      <td>soil_type_29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cover_Type</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               0             1             2  \\\n",
       "Elevation                                   2596          2590          2804   \n",
       "Aspect                                        51            56           139   \n",
       "Slope                                          3             2             9   \n",
       "Horizontal_Distance_To_Hydrology             258           212           268   \n",
       "Vertical_Distance_To_Hydrology                 0            -6            65   \n",
       "Horizontal_Distance_To_Roadways              510           390          3180   \n",
       "Hillshade_9am                                221           220           234   \n",
       "Hillshade_Noon                               232           235           238   \n",
       "Hillshade_3pm                                148           151           135   \n",
       "Horizontal_Distance_To_Fire_Points          6279          6225          6121   \n",
       "Wilderness_Area                      area_type_1   area_type_1   area_type_1   \n",
       "Soil_Type                           soil_type_29  soil_type_29  soil_type_12   \n",
       "Cover_Type                                     4             4             1   \n",
       "\n",
       "                                               3             4  \n",
       "Elevation                                   2785          2595  \n",
       "Aspect                                       155            45  \n",
       "Slope                                         18             2  \n",
       "Horizontal_Distance_To_Hydrology             242           153  \n",
       "Vertical_Distance_To_Hydrology               118            -1  \n",
       "Horizontal_Distance_To_Roadways             3090           391  \n",
       "Hillshade_9am                                238           220  \n",
       "Hillshade_Noon                               238           234  \n",
       "Hillshade_3pm                                122           150  \n",
       "Horizontal_Distance_To_Fire_Points          6211          6172  \n",
       "Wilderness_Area                      area_type_1   area_type_1  \n",
       "Soil_Type                           soil_type_30  soil_type_29  \n",
       "Cover_Type                                     1             4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soil_type_values = [f\"soil_type_{idx+1}\" for idx in range(40)]\n",
    "wilderness_area_values = [f\"area_type_{idx+1}\" for idx in range(4)]\n",
    "\n",
    "soil_type = raw_data.loc[:, 14:53].apply(\n",
    "    lambda x: soil_type_values[0::1][x.to_numpy().nonzero()[0][0]], axis=1\n",
    ")\n",
    "wilderness_area = raw_data.loc[:, 10:13].apply(\n",
    "    lambda x: wilderness_area_values[0::1][x.to_numpy().nonzero()[0][0]], axis=1\n",
    ")\n",
    "\n",
    "CSV_HEADER = [\n",
    "    \"Elevation\",\n",
    "    \"Aspect\",\n",
    "    \"Slope\",\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Vertical_Distance_To_Hydrology\",\n",
    "    \"Horizontal_Distance_To_Roadways\",\n",
    "    \"Hillshade_9am\",\n",
    "    \"Hillshade_Noon\",\n",
    "    \"Hillshade_3pm\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\",\n",
    "    \"Wilderness_Area\",\n",
    "    \"Soil_Type\",\n",
    "    \"Cover_Type\",\n",
    "]\n",
    "\n",
    "data = pd.concat(\n",
    "    [raw_data.loc[:, 0:9], wilderness_area, soil_type, raw_data.loc[:, 54]],\n",
    "    axis=1,\n",
    "    ignore_index=True,\n",
    ")\n",
    "data.columns = CSV_HEADER\n",
    "\n",
    "# Convert the target label indices into a range from 0 to 6 (there are 7 labels in total).\n",
    "data[\"Cover_Type\"] = data[\"Cover_Type\"] - 1\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "data.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5c65102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split size: 493728\n",
      "Test split size: 87284\n"
     ]
    }
   ],
   "source": [
    "train_splits = []\n",
    "test_splits = []\n",
    "\n",
    "for _, group_data in data.groupby(\"Cover_Type\"):\n",
    "    random_selection = np.random.rand(len(group_data.index)) <= 0.85\n",
    "    train_splits.append(group_data[random_selection])\n",
    "    test_splits.append(group_data[~random_selection])\n",
    "\n",
    "train_data = pd.concat(train_splits).sample(frac=1).reset_index(drop=True)\n",
    "test_data = pd.concat(test_splits).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(f\"Train split size: {len(train_data.index)}\")\n",
    "print(f\"Test split size: {len(test_data.index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aca5bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = \"train_data.csv\"\n",
    "test_data_file = \"test_data.csv\"\n",
    "\n",
    "train_data.to_csv(train_data_file, index=False)\n",
    "test_data.to_csv(test_data_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ff854fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_FEATURE_NAME = \"Cover_Type\"\n",
    "\n",
    "TARGET_FEATURE_LABELS = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]\n",
    "\n",
    "NUMERIC_FEATURE_NAMES = [\n",
    "    \"Aspect\",\n",
    "    \"Elevation\",\n",
    "    \"Hillshade_3pm\",\n",
    "    \"Hillshade_9am\",\n",
    "    \"Hillshade_Noon\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\",\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Horizontal_Distance_To_Roadways\",\n",
    "    \"Slope\",\n",
    "    \"Vertical_Distance_To_Hydrology\",\n",
    "]\n",
    "\n",
    "CATEGORICAL_FEATURES_WITH_VOCABULARY = {\n",
    "    \"Soil_Type\": list(data[\"Soil_Type\"].unique()),\n",
    "    \"Wilderness_Area\": list(data[\"Wilderness_Area\"].unique()),\n",
    "}\n",
    "\n",
    "CATEGORICAL_FEATURE_NAMES = list(CATEGORICAL_FEATURES_WITH_VOCABULARY.keys())\n",
    "\n",
    "FEATURE_NAMES = NUMERIC_FEATURE_NAMES + CATEGORICAL_FEATURE_NAMES\n",
    "\n",
    "COLUMN_DEFAULTS = [\n",
    "    [0] if feature_name in NUMERIC_FEATURE_NAMES + [TARGET_FEATURE_NAME] else [\"NA\"]\n",
    "    for feature_name in CSV_HEADER\n",
    "]\n",
    "\n",
    "NUM_CLASSES = len(TARGET_FEATURE_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "745a34d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_from_csv(csv_file_path, batch_size, shuffle=False):\n",
    "\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        csv_file_path,\n",
    "        batch_size=batch_size,\n",
    "        column_names=CSV_HEADER,\n",
    "        column_defaults=COLUMN_DEFAULTS,\n",
    "        label_name=TARGET_FEATURE_NAME,\n",
    "        num_epochs=1,\n",
    "        header=True,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return dataset.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc7733d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "dropout_rate = 0.1\n",
    "batch_size = 265\n",
    "num_epochs = 50\n",
    "\n",
    "hidden_units = [32, 32]\n",
    "\n",
    "\n",
    "def run_experiment(model):\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "\n",
    "    train_dataset = get_dataset_from_csv(train_data_file, batch_size, shuffle=True)\n",
    "\n",
    "    test_dataset = get_dataset_from_csv(test_data_file, batch_size)\n",
    "\n",
    "    print(\"Start training the model...\")\n",
    "    history = model.fit(train_dataset, epochs=num_epochs)\n",
    "    print(\"Model training finished\")\n",
    "\n",
    "    _, accuracy = model.evaluate(test_dataset, verbose=0)\n",
    "\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d7a46c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        if feature_name in NUMERIC_FEATURE_NAMES:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.float32\n",
    "            )\n",
    "        else:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.string\n",
    "            )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1947fb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import StringLookup\n",
    "\n",
    "\n",
    "def encode_inputs(inputs, use_embedding=False):\n",
    "    encoded_features = []\n",
    "    for feature_name in inputs:\n",
    "        if feature_name in CATEGORICAL_FEATURE_NAMES:\n",
    "            vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]\n",
    "            # Create a lookup to convert string values to an integer indices.\n",
    "            # Since we are not using a mask token nor expecting any out of vocabulary\n",
    "            # (oov) token, we set mask_token to None and  num_oov_indices to 0.\n",
    "            lookup = StringLookup(\n",
    "                vocabulary=vocabulary,\n",
    "                mask_token=None,\n",
    "                num_oov_indices=0,\n",
    "                output_mode=\"int\" if use_embedding else \"binary\",\n",
    "            )\n",
    "            if use_embedding:\n",
    "                # Convert the string input values into integer indices.\n",
    "                encoded_feature = lookup(inputs[feature_name])\n",
    "                embedding_dims = int(math.sqrt(len(vocabulary)))\n",
    "                # Create an embedding layer with the specified dimensions.\n",
    "                embedding = layers.Embedding(\n",
    "                    input_dim=len(vocabulary), output_dim=embedding_dims\n",
    "                )\n",
    "                # Convert the index values to embedding representations.\n",
    "                encoded_feature = embedding(encoded_feature)\n",
    "            else:\n",
    "                # Convert the string input values into a one hot encoding.\n",
    "                encoded_feature = lookup(tf.expand_dims(inputs[feature_name], -1))\n",
    "        else:\n",
    "            # Use the numerical features as-is.\n",
    "            encoded_feature = tf.expand_dims(inputs[feature_name], -1)\n",
    "\n",
    "        encoded_features.append(encoded_feature)\n",
    "\n",
    "    all_features = layers.concatenate(encoded_features)\n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0dc0acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "def create_baseline_model():\n",
    "    inputs = create_model_inputs()\n",
    "    features = encode_inputs(inputs)\n",
    "\n",
    "    for units in hidden_units:\n",
    "        features = layers.Dense(units)(features)\n",
    "        features = layers.BatchNormalization()(features)\n",
    "        features = layers.ReLU()(features)\n",
    "        features = layers.Dropout(dropout_rate)(features)\n",
    "\n",
    "    outputs = layers.Dense(units=NUM_CLASSES, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "baseline_model = create_baseline_model()\n",
    "keras.utils.plot_model(baseline_model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "865f89c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydot\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pydot) (3.0.4)\n",
      "Installing collected packages: pydot\n",
      "Successfully installed pydot-1.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89112de0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/50\n",
      "1864/1864 [==============================] - 19s 9ms/step - loss: 0.7758 - sparse_categorical_accuracy: 0.6784\n",
      "Epoch 2/50\n",
      "1864/1864 [==============================] - 16s 9ms/step - loss: 0.6648 - sparse_categorical_accuracy: 0.7144\n",
      "Epoch 3/50\n",
      "1864/1864 [==============================] - 16s 9ms/step - loss: 0.6392 - sparse_categorical_accuracy: 0.7259\n",
      "Epoch 4/50\n",
      "1864/1864 [==============================] - 19s 10ms/step - loss: 0.6184 - sparse_categorical_accuracy: 0.7348\n",
      "Epoch 5/50\n",
      "1864/1864 [==============================] - 15s 8ms/step - loss: 0.6033 - sparse_categorical_accuracy: 0.7410\n",
      "Epoch 6/50\n",
      "1864/1864 [==============================] - 15s 8ms/step - loss: 0.5953 - sparse_categorical_accuracy: 0.7443\n",
      "Epoch 7/50\n",
      "1864/1864 [==============================] - 19s 10ms/step - loss: 0.5888 - sparse_categorical_accuracy: 0.7474\n",
      "Epoch 8/50\n",
      "1864/1864 [==============================] - 16s 9ms/step - loss: 0.5842 - sparse_categorical_accuracy: 0.7493\n",
      "Epoch 9/50\n",
      "1864/1864 [==============================] - 16s 9ms/step - loss: 0.5800 - sparse_categorical_accuracy: 0.7504\n",
      "Epoch 10/50\n",
      "1864/1864 [==============================] - 19s 10ms/step - loss: 0.5757 - sparse_categorical_accuracy: 0.7522\n",
      "Epoch 11/50\n",
      "1864/1864 [==============================] - 17s 9ms/step - loss: 0.5732 - sparse_categorical_accuracy: 0.7532\n",
      "Epoch 12/50\n",
      "1864/1864 [==============================] - 17s 9ms/step - loss: 0.5703 - sparse_categorical_accuracy: 0.7546\n",
      "Epoch 13/50\n",
      "1864/1864 [==============================] - 17s 9ms/step - loss: 0.5677 - sparse_categorical_accuracy: 0.7551\n",
      "Epoch 14/50\n",
      "1864/1864 [==============================] - 19s 10ms/step - loss: 0.5656 - sparse_categorical_accuracy: 0.7570\n",
      "Epoch 15/50\n",
      "1864/1864 [==============================] - 16s 9ms/step - loss: 0.5635 - sparse_categorical_accuracy: 0.7574\n",
      "Epoch 16/50\n",
      "1864/1864 [==============================] - 16s 9ms/step - loss: 0.5607 - sparse_categorical_accuracy: 0.7579\n",
      "Epoch 17/50\n",
      "1864/1864 [==============================] - 20s 11ms/step - loss: 0.5597 - sparse_categorical_accuracy: 0.7591\n",
      "Epoch 18/50\n",
      "1864/1864 [==============================] - 19s 10ms/step - loss: 0.5580 - sparse_categorical_accuracy: 0.7595\n",
      "Epoch 19/50\n",
      "1864/1864 [==============================] - 16s 8ms/step - loss: 0.5580 - sparse_categorical_accuracy: 0.7599\n",
      "Epoch 20/50\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 0.5553 - sparse_categorical_accuracy: 0.7612\n",
      "Epoch 21/50\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 0.5545 - sparse_categorical_accuracy: 0.7612\n",
      "Epoch 22/50\n",
      "1864/1864 [==============================] - 18s 9ms/step - loss: 0.5535 - sparse_categorical_accuracy: 0.7623\n",
      "Epoch 23/50\n",
      "1864/1864 [==============================] - 15s 8ms/step - loss: 0.5521 - sparse_categorical_accuracy: 0.7629\n",
      "Epoch 24/50\n",
      "1864/1864 [==============================] - 15s 8ms/step - loss: 0.5510 - sparse_categorical_accuracy: 0.7631\n",
      "Epoch 25/50\n",
      "1864/1864 [==============================] - 19s 10ms/step - loss: 0.5499 - sparse_categorical_accuracy: 0.7636\n",
      "Epoch 26/50\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 0.5491 - sparse_categorical_accuracy: 0.7632\n",
      "Epoch 27/50\n",
      "1864/1864 [==============================] - 17s 9ms/step - loss: 0.5481 - sparse_categorical_accuracy: 0.7642\n",
      "Epoch 28/50\n",
      "1864/1864 [==============================] - 16s 9ms/step - loss: 0.5469 - sparse_categorical_accuracy: 0.7653\n",
      "Epoch 29/50\n",
      "1864/1864 [==============================] - 17s 9ms/step - loss: 0.5457 - sparse_categorical_accuracy: 0.7656\n",
      "Epoch 30/50\n",
      "1864/1864 [==============================] - 19s 10ms/step - loss: 0.5449 - sparse_categorical_accuracy: 0.7652\n",
      "Epoch 31/50\n",
      "1864/1864 [==============================] - 17s 9ms/step - loss: 0.5446 - sparse_categorical_accuracy: 0.7662\n",
      "Epoch 32/50\n",
      "1864/1864 [==============================] - 19s 10ms/step - loss: 0.5431 - sparse_categorical_accuracy: 0.7669\n",
      "Epoch 33/50\n",
      "1864/1864 [==============================] - 19s 10ms/step - loss: 0.5425 - sparse_categorical_accuracy: 0.7665\n",
      "Epoch 34/50\n",
      "1864/1864 [==============================] - 17s 9ms/step - loss: 0.5428 - sparse_categorical_accuracy: 0.7669\n",
      "Epoch 35/50\n",
      "1864/1864 [==============================] - 14s 8ms/step - loss: 0.5406 - sparse_categorical_accuracy: 0.7679\n",
      "Epoch 36/50\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 0.5409 - sparse_categorical_accuracy: 0.7681\n",
      "Epoch 37/50\n",
      " 791/1864 [===========>..................] - ETA: 8s - loss: 0.5391 - sparse_categorical_accuracy: 0.7680"
     ]
    }
   ],
   "source": [
    "run_experiment(baseline_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5d006d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
